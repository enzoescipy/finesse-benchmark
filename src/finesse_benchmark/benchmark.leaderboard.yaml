# Finesse Benchmark: Official Leaderboard Configuration

# This YAML serves as the official standard configuration for leaderboard submissions.
# To submit results, copy this file to benchmark.yaml and run the evaluation.
# It ensures fairness, reproducibility, and alignment with Finesse's core philosophy of evaluating
# composition (synthesis) without artificial masking.

# Do NOT modify this file for submissions. Use it as-is for standardized scoring.

mode: "merger_mode"  # Standard: merger_mode for sequence-merger evaluations. Change only if comparing native/BYOK modes explicitly.

# Models Configuration (Standard for Leaderboard)
models:
  # Sequence Merger (core for merger_mode)
  merger:
    name: "enzoescipy/sequence-merger-malgeum"  # Official merger model; use your fine-tuned variant if submitting custom
  # Base Embedder (used in merger_mode and as probe embedder)
  base_embedder:
    name: "intfloat/multilingual-e5-base"  # Standard multilingual base for global coverage
  # Native Embedder (for native_mode comparisons)
  native_embedder:
    name: "Snowflake/snowflake-arctic-embed-l-v2.0"  # Reference long-context embedder

  # [BYOK Mode Example - Uncomment and edit for BYOK usage]
  # For byok_mode: Specify the API provider and model name for litellm
  # byok_embedder:
  #   provider: "openai"  # e.g., 'openai', 'cohere', 'google'
  #   name: "text-embedding-3-large"  # Provider-specific model name
  #   tokenizer_path: null  # Optional: Hugging Face tokenizer path for accurate token counting
  #                        # e.g., 'Cohere/cohere-tokenizer-fast' for Cohere models
  #                        # If null, system will use tiktoken for OpenAI or fallback with warning
  #
  # IMPORTANT: API keys MUST be set as environment variables for security.
  # Do NOT store keys in this YAML file or commit them to version control.
  # Examples (set in your terminal before running):
  #
  # For OpenAI:
  #   export OPENAI_API_KEY="sk-your-key-here"  # Linux/macOS
  #   $env:OPENAI_API_KEY="sk-your-key-here"  # Windows PowerShell
  #
  # For Cohere:
  #   export COHERE_API_KEY="your-cohere-key-here"
  #
  # For Google:
  #   export GOOGLE_API_KEY="your-google-key-here"
  #
  # Tokenizer Recommendations:
  # - OpenAI models: Leave tokenizer_path null (uses tiktoken automatically)
  # - Cohere models: Set tokenizer_path: "Cohere/cohere-tokenizer-fast"
  # - Google models: Set tokenizer_path: "google-bert/bert-base-uncased" or similar
  #
  # litellm will automatically detect and use the appropriate environment variable
  # based on the 'provider' you specify. This ensures your keys remain secure.

# Dataset Configuration (Fixed for Reproducibility)
dataset:
  path: "enzoescipy/finesse-benchmark-database"  # Official dataset
  split: "train"  # Use train split for consistency
  commit_hash: "e76559cba6d9848735ab801c2b6ea08d13d6fb73"

# Probe Configuration (Standard for Leaderboard)
# Balances short-to-medium sequence evaluation with sufficient samples for statistical significance
probe_config:
  sequence_length:
    min: 4   # Minimum length: Tests basic composition
    max: 64  # Maximum length: Tests scaling up to moderate long-context
  samples_per_length: 25  # Samples per length: Ensures reliable averages (25 evals per point)
  token_per_sample : 512  # Number of tokens per chunk

# Advanced Settings (Defaults for Fair Comparison)
advanced:
  batch_size: 8   # Efficient batching; adjust based on hardware
  device: "cuda"   # Use GPU if available; falls back to CPU

# Seed for Reproducibility (Immutable for Leaderboard)
seed: 42  # Fixed seed: Ensures identical dataset shuffling and randomness across runs
